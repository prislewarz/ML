import torch
x = torch.arange(12, dtype=torch.float32)
x.numel()
x.shape
X = x.reshape(3, 4)

torch.zeros((2, 3, 4))
torch.ones((2, 3, 4))
torch.randn(3, 4)
torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])

print(X[-1])
print(X[1:3])
X[1, 2] = 17
X[:2, :] = 12


torch.exp(X)
x = torch.tensor([1.0, 2, 4, 8])
y = torch.tensor([2, 2, 2, 2])
x + y, x - y, x * y, x / y, x ** y
x == y
x.sum()

import numpy as np
t = np.array([[[0, 1, 2],
               [3, 4, 5]],
              [[6, 7, 8],
               [9, 10, 11]]])
ft = torch.FloatTensor(t)
print(ft.shape)
print(ft.view([-1, 3]))
print(ft.view([-1, 3]).shape)
ft = torch.FloatTensor([[0], [1], [2]])
print(ft)
print(ft.shape)
print(ft.squeeze())
print(ft.squeeze().shape)
ft = torch.Tensor([0, 1, 2])
print(ft.shape)
print(ft.unsqueeze(0))
print(ft.unsqueeze(0).shape)
print(ft.view(1, -1))
print(ft.view(1, -1).shape)
print(ft.unsqueeze(1))
print(ft.unsqueeze(1).shape)
print(ft.unsqueeze(-1))
print(ft.unsqueeze(-1).shape)

x = torch.FloatTensor([[1, 2], [3, 4]])
y = torch.FloatTensor([[5, 6], [7, 8]])
print(torch.cat([x, y], dim=0))
print(torch.cat([x, y], dim=1))
x = torch.FloatTensor([1, 4])
y = torch.FloatTensor([2, 5])
z = torch.FloatTensor([3, 6])
print(torch.stack([x, y, z]))
print(torch.cat([x.unsqueeze(0), y.unsqueeze(0), z.unsqueeze(0)], dim=0))
print(torch.stack([x, y, z], dim=1))

tensor = torch.rand(3,6)
print(tensor)
t1, t2, t3 = torch.chunk(tensor, 3, dim=1)
print(t1)
print(t2)
print(t3)
tensor = torch.rand(3,6)
print(tensor)
t1, t2 = torch.split(tensor, 3, dim=1)
print(t1)
print(t2)

A = torch.arange(6).reshape(3, 2)
A.T
A = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])
A == A.T

A.sum()
A.shape, A.sum(axis=0)
A.shape, A.sum(axis=1)
A.sum(axis=[0, 1]) == A.sum()
sum_A = A.sum(axis=1, keepdims=True)
sum_A, sum_A.shape
A / sum_A
A.cumsum(axis=0)

x = torch.arange(3, dtype=torch.float32)
y = torch.ones(3, dtype = torch.float32)
x, y, torch.dot(x, y)
A = torch.arange(6, dtype=torch.float32).reshape(2, 3)
A.shape, x.shape, torch.mv(A, x), A@x
B = torch.ones(3, 4)
torch.mm(A, B), A@B

u = torch.tensor([3.0, -4.0])
torch.norm(u)
torch.abs(u).sum()
torch.ones((4, 9))
torch.norm(torch.ones((4, 9)))
torch.norm(torch.arange(4,dtype=torch.float32).reshape(2,2))

x = torch.arange(4.0)
x.requires_grad_(True)
x.grad 
y = 2 * torch.dot(x, x)
y.backward()
x.grad
x.grad == 4 * x
x.grad.zero_()  # Reset the gradient
y = x.sum()
y.backward()
x.grad
x.grad.zero_()
y = x * x
y.backward(gradient=torch.ones(len(y)))  # Faster: y.sum().backward()
x.grad
x.grad.zero_()
y = x * x
u = y.detach()
z = u * x
z.sum().backward()
x.grad == u
